## Over Sampling이란?
> 소수의 클래스의 샘플을 복제하여 다수 클래스와의 균형을 맞추는 리샘플링 기법.

오버 샘플링(Over-Sampling)이란 인공지능을 학습시킬 때, 학습 데이터의 클래스 간에 불균형이 발생할 때 소수 클래스의 샘플을 반복 또는 생성하여 다수 클래스와 균형을 맞추는 리샘플링 기법이다.

즉, 소수의 클래스의 샘플을 복제하여 다수 클래스와의 균형을 맞추는 것이다.

### 오버 샘플링의 장점
오버 샘플링은 정보 손실이 없고, 모든 원본 데이터를 활용하며, 소수 클래스의 중요한 패턴을 강화할 수 있다.
### 오버 샘플링의 단점
더 많은 데이터를 만들어 학습하기에 메모리 사용량이 증가한다.

### 오버 샘플링 종류
- Random Oversampling
	- 랜덤 오버 샘플링은 소수 클래스 샘플을 무작위로 복제하는 방법이다. 하지만 1:100 불균형을 1:1로 만들려면 소수 클래스를 100번 복제해야 하며, 이는 과적합 위험을 높인다.

### 실제 적용 시
실제 적용 시에는 완벽한 균형(1:1)보다는 부분적 균형(1:10 -> 1:3)이 더 효과적인 경우가 많으며, 이는 실제 분포를 반영하면서 학습을 개선한다.

또한, 오버 샘플링은 학습 데이터에만 적용해야 하며, 검증/테스트 데이터는 원본 분포를 유지해야 실제 성능을 정확히 평가할 수 있음